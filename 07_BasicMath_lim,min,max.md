# 함수의 극한과 최대, 최소

## 미분

### 1. 역전파 알고리즘 (Backpropagation) 

- 다층 퍼셉트론 형태: 입력층 - 은닉층 - 은닉층 - ... - 출력층
  - 입력층(input): 데이터가 입력되는 층
  - 은닉층(hidden): 복잡한 분류 문제에서 판별 경계를 찾는 층
  - 출력층(output): 활성화 함수 값을 계산하여 출력하는 층
    - 출력값(ŷ): 예측한 값(predicted value)
    - 관측값(y)
- 최적화(optimization): ŷ = wx + b 에서 관측값(y)과 차이를 0에 가깝게 만드는 과정
- 오차역전법: 동일 입력층에 대해 원하는 값이 출력되도록 가중치, 편향 값을 조정하는 방법
  - 가중치(w, weight): 결과에 주는 영향력을 조절하는 요소
  - 가중합(weighted sum): 입력값과 가중치의 곱을 모두 더하고 그 위에 편향을 더한 값
  - 편향(b, bias): 가중합에 더하는 상수(constant)
  - 학습률(η, learning rate): 학습할 때 얼만큼의 변화를 주는지에 대한 상수, 기울기
- 활성화함수(activation function): 가중합의 결과로 0 or 1을 출력하는데, 그 값을 판단하는 함수
  - 시그모이드(Sigmoid function)
  - 렐루(ReLU function) - rectify 수정v

### 2. 미분의 사용

- 원 값을 구하기 위해 입력값, 가중치, 편향, 활성화 함수를 알아야 함
  - 입력값
  - 활성화함수: 가중합으로 알 수 있음
- 가중치와 편향을 구하기 위해 역전파를 사용하는데, 이 과정에서 미분을 사용
  - 출력값 = -1, 입력값\*가중치 >= 0 
    가중치업데이트 = 가중치 - (학습률\*입력값)
  - 출력값 = 1, 입력값\*가중치 <= 0
    가중치업데이트 = 가중치 + (학습률\*입력값)
- *f*'`(a) ; 기울기, 접선의 기울기, 미분값, 미분계수
  - y의 증가량 / x의 증가량
  - *f*(a+h)-*f*(a) / (a+h)-a